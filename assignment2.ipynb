{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1z1M1UQapMBUIvMLgW2eX_yfUGTZGzyA6",
      "authorship_tag": "ABX9TyPlwMFmX8Ap2qyHGu0bAGoa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdiY2j/CS6910_Assignment2/blob/main/assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx8Dds_hBsU6",
        "outputId": "2070d3b1-c234-49e7-95a7-31d942145b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "DTXQgMohM-u5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFiP7KVdNOAD",
        "outputId": "eaaa2a29-0f4b-43bd-d1b1-58eadfeb8299"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ExGO_PmZNeMp",
        "outputId": "41f10214-2bca-4769-da5f-cefb0faf8474"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the directory containing your dataset\n",
        "dataset_dir = '/content/drive/MyDrive/inaturalist_12K'\n",
        "\n",
        "data_aug = False\n",
        "\n",
        "if data_aug :\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "else :\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "# Create a PyTorch dataset from the image folder\n",
        "dataset = ImageFolder(dataset_dir, transform=transform)\n",
        "\n",
        "\n",
        "validation_ratio = 0.2\n",
        "class_labels = [label for _, label in dataset]\n",
        "\n",
        "# Create a dictionary to store indices for each class\n",
        "class_indices = defaultdict(list)\n",
        "for idx, label in enumerate(class_labels):\n",
        "    class_indices[label].append(idx)\n",
        "\n",
        "# Initialize lists to store training and validation indices\n",
        "train_indices = []\n",
        "val_indices = []\n",
        "\n",
        "# Split each class into training and validation indices\n",
        "for label, indices in class_indices.items():\n",
        "    num_samples = len(indices)\n",
        "    num_validation_samples = int(validation_ratio * num_samples)\n",
        "    np.random.shuffle(indices)  # Shuffle indices for random selection\n",
        "    train_indices.extend(indices[num_validation_samples:])\n",
        "    val_indices.extend(indices[:num_validation_samples])\n",
        "\n",
        "# Create SubsetRandomSampler for training and validation sets\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "# Create dataloaders for training and validation sets\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n"
      ],
      "metadata": {
        "id": "Oa_JvoClCACI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jFzi5NkiCk8r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}